# chess_rl/config.yaml
model:
  model_path: "../model/transformer_model.py" # Relative path to your model definition
  config_path: "../model/config.json"        # Path to your model's config (e.g., dimensions)
  checkpoint_dir: "checkpoints/"             # Directory to save/load model state_dicts
  latest_checkpoint_name: "latest_model.pt"

mcts:
  num_simulations: 100         # Number of MCTS simulations per move
  cpuct: 1.0                  # Exploration constant (c_puct in PUCT formula)
  temperature_start: 1.0      # Initial temperature for sampling moves during self-play (exploration)
  temperature_end: 0.0        # Final temperature (deterministic play after N moves)
  temp_decay_moves: 30        # Number of moves to decay temperature over
  top_k_filtering: 0.95       # Keep moves covering this cumulative probability mass

self_play:
  num_games_per_cycle: 100    # Number of games to generate per self-play cycle
  max_game_length: 300        # Maximum moves per game to prevent infinite loops
  replay_buffer_dir: "replay_buffer/" # Directory to store game data
  start_pos_fen_files: null   # Optional: List of files containing FENs for starting positions (e.g., ["endgames.fen"])

training:
  batch_size: 128
  learning_rate: 1e-4
  weight_decay: 1e-5
  policy_loss_weight: 1.0
  value_loss_weight: 1.0      # Lambda in your loss formula
  max_epochs: 1               # Train for 1 epoch over the new data each cycle
  buffer_sample_fraction: 0.5 # Fraction of buffer to use for training each cycle (adjust based on buffer size)
  accelerator: "gpu"
  devices: 1

pipeline:
  num_cycles: 50              # Total number of self-play -> training cycles